# 키-값 저장소 설계

* KEY-VALUE STORE 라고도 부르며 비관계형 데이터베이스이다. 고유 식별자를 키로 가져야 하고, 키와 값 사이의 연결관계를 키-값 쌍이라고 한다.
* 키는 유일해야 하며 값은 키를 통해서만 접근 가능하다. 짧을 수록 좋다.
* 값은 문자열, 리스트, 객체일수도 있고 대부분 무엇이 오든 상관하지 않는다.
* 서비스 예시로는 Amazon DynamoDB, memcached, redis 가 있다.

## 단일 서버 키-값 저장소

* 가장 단순하게 구현하려면 해시 테이블을 사용하는 것이다.
* 아래 두 가지 방법을 사용할 수 있으나 그래도 결국 한 대의 서버로는 부족하고 분산 키-값 저장소가 필요하다.
    * 압축
    * 자주쓰는 데이터만 메모리에 두고 나머지는 디스크에 저장

## 분산 키-값 저장소

### CAP

* Consistency, Availability, Partition Tolerance 의 약자다.
* CAP 중 3가지 중 2가지를 만족하려면 1가지를 희생해야 한다
* 키-값 스토어는
    * CP: 일관성과 파티션 감내를 지원하며 저장소로 가용성을 희생한다(몽고디비)
    * AP: 가용성과 파티션 감내를 지원하며 데이터 일관성을 희생한다(카산드라)
    * CA: 일관성과 가용성을 지원한다. 실제 세계에서는 네트워크 장애는 피할 수 없기 때문에 대부분의 분산 시스템은 파티션 감내할 수 있도록 설계되어 CA는 거의 존재하지 않는다.
* 이상적 상태는 n1(master), n2, n3 라면 n1에 기록된 데이터는 자동적으로 n2, n3에 복제된다. 데이터 일관성, 가용성도 보장된다.
* 실세계 분산 시스템
    * 파티션 문제를 피할 수 없고 발생한다면 일관성과 가용성 중 하나를 선택해야 한다.
    * 마스터에 문제가 생겼다면 슬레이브는 오래된 사본을 갖고 있다.
        * 카프카는 producer ack
        * 몽고디비는 writeConcern
        * 으로 어디까지 저장할지 지정할 수 있다. 또한 마스터에 문제가 생겼을시 마스터를 재선출한다.
    * 데이터 일관성을 선택한다면 쓰기연산은 중단된다.
    * 가용성을 선택한다면 읽기 연산을 허용한다.
* CAP 확장인 PACELC theorem 이 존재한다

### 시스템 컴포넌트

* 데이터 파티션
    * 데이터를 파티션 단위로 나눈다.
    * 몽고디비는 샤딩을 지원하며 이 때 컨피그 서버가 따로 필요하다
* 데이터 다중화
    * 5장의 해시링에서 가상노드하나에 여러 서버들이 붙어있다면 캐시키가 여러곳에 저장되어 다주오하를 이룰 수 있다.
    * 데이터의 사본은 다른 센터의 서버에 보관하고 센터들을 고속 네트워크로 연결한다.
* 일관성
    * 데이터 동기화를 위해 Quorum Consensus 프로토콜을 사용할 수 있다. 최근엔 raft 협의 알고리즘도 많이 도입되었다.
    * N = 사본 개수
    * W = 쓰기 연산에 대한 정족수
    * R = 읽기 연산에 대한 정족수
    * W=1 or R=1 이면 중재자는 한 대서버로부터의 응답만 받으면 되기 때문에 응답속도가 빠르다. 1보다 크다면 일관성의 수준은 향상되지만 응답속도가 느려진다
    * W+R>N 이라면 일관성을 보증할 최신데이터를 가진 노드가 하나이상 겹치기 때문에 강한 일관성을 갖는다.
    * 일관성모델에는
        * 강한 일관성: 낡은 데이터를 읽어가는 일이 없다
        * 약한 일관성: 최근 갱신된 데이터를 읽지 못할 수도 있다
        * 최종 일관성: 최종적으로는 모든 사본에 반영된다.
* 일관성 불일치 해소
    * 데이터 버저닝
        * 데이터별로 버저닝을 해서 각 버전의 데이터를 불변으로 만든다.
    * 벡터 시계
* 장애 처리
    * 장애감지
        * 두 대 이상의 서버가 죽어야 서버가 죽었다고 판단한다.
            * 별로 좋지 않다. 한 대가 죽으면 다른 곳에 부하가 몰린다. 다시 문제가 발생함
        * 가십 프로토콜은 같은 분산형 장애감지 솔루션이 있다.
            * 각 노드는 멤버십 목록을 유지하고 하트비트 카운터가 있다.
            * 하트비트 카운터가 지정시간동안 증가하지 않으면 장애로 간주한다.
                * 카프카컨슈머 - 브로커 사이의 장애감지 중 하나
        * 일시적 장애 처리
            * 엄격한 정족수 접근법을 쓴다면 읽기/쓰기 연산을 금지해야 한다.
            * 느슨한 정족수라면 W개의 건강한 쓰기연산할 서버와 R 개의 일기연산할 건강한 서버를 고른다. 임시로 쓰기 연산을 처리한 서버에는 힌트를 남겨둔다. 이를 단서후 임시 위탁 기법이라 한다.
        * 영구 장애 처리
            * 반 엔트로피 프로토콜을 구현한다.
                * 사본들을 비교하여 최신 버전으로 갱신
                * 사본간의 일관성이 망가진 상태를 감지하고 전송 데이터 양을 줄이기 위해 머클 트리를 사용한다
                    * 머클트리는 해시트리로도 불리운다
                    * 해시트리를 통해 자료구조내부의 내용을 효과적이고 안전하게 검증할 수 있다.
                    * 머클트리를 사용하면 동기화해야하는 데이터의 양은 실제로 존재하는 차이에 비례할 뿐 데이터 총량과는 무관해진다.
        * 데이터 센터 장애처리
            * 다중화하자
* 시스템 아키텍쳐 다이어그램
    * 클라이언트는 두 가지 단순한 API get,put로 통신한다
    * 중개자는클라이언트에게 프락시 역할을 한다
    * 노드는 안정해시의 해시링에 분포한다.
    * 노드를 자동으로 추가 삭제할 수 있도록 시스템은 분산된다
    * 데이터는 여러 노드에 다중화된다
    * 모든 노드가 같은 책임을 지므로 SPOF 는 존재하지 않는다.
* 쓰기경로
    * 쓰기 요청이 특정 노드에 전달되면
        * 쓰기 요청이 커밋 로그에 기록된다
        * 메모리 캐시에 기록된다
        * 메모리 캐시가 임계치에 도달하면 데이터는 디스크에 저장된다.
* 읽기경로
    * 데이터가 메모리에 없다면 디스크에서 가져온다.
        * 블룸필터가 키가 SSTable 에서 어디 있는지 찾는데 도움이 된다
    * 데이터를 가져와서 클라이언트에 반환한다.

