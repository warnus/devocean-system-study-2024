# 처리율 제한 장치의 설계
* 네트워크 시스템에서 Rate Limiter 는 클라이언트 또는 서비스가 보내는 처리율을 제어하기 위한 장치다.
* API 요청횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다.

## 처리율 제한 장치의 장점
* DoS 공격에 의한 자원고갈을 방지할 수 있다.
    * 구글독스 read api, 트위터 트윗올리기 등이 임계치를 넘은 요청은 중단한다
* 비용을 절감한다. 우선순위가 높은 API 에 더 많은 자원을 할당하며 외부 API와 연동중이라면 사용량에 따라 과금된다면 횟수 제한이 필수적이다
* 서버 과부하를 막는다. 봇에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러내는데 처리율 제한 장치를 활용할 수 있다.

## 4단계 접근법

### 1. 문제 이해 및 설계 범위 확정
* 서버 or 클라이언트 => 서버측 처리율 제한 장치
* 어떤 기준으로 제어해야 하는가? IP 주소, 사용자 Id 등 => 다양한 제어 규칙을 정의할 수 있는 유연한 시스템
* 시스템 규모 => 대용량
* 분산환경
* 독립된 서비스 vs 애플리케이션 코드 내 포함
* 사용자 알림
* 요약
    * 설정된 처리율을 초과하는 요청은 정확하게 제한
    * 낮은 응답시간: Http 응답시간에 영향을 주어서는 안된다
    * 하나의 처리율 제한 장치를 여러 서버나 프로세스에 공유할 수 있어야 한다
    * 예외처리
    * 결함 감내성(fault tolerance): 제한장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다

### 2. 개략적 설계안 제시 및 동의 구하기
* 클라이언트에 두는 것은 안정적으로 제한을 걸기 어렵다. 서버측에 둬보자
* API 서버에 두는 대신 미들웨어를 만들어서 API 서버로 가는 요청을 통제하도록 하자
    * 제한을 초과한다면 Too Many Request 429 를 내려주자
    * API Gateway 에 둘 수도 있다.
        * [참고](https://velog.io/@qwerty1434/%EB%84%A4%EC%9D%B4%EB%B2%84-D2-11%EB%B2%88%EA%B0%80-Spring-Cloud-%EA%B8%B0%EB%B0%98-MSA%EB%A1%9C%EC%9D%98-%EC%A0%84%ED%99%98-%EC%A7%80%EB%82%9C-1%EB%85%84%EA%B0%84%EC%9D%98-%EC%9D%B4%EC%95%BC%EA%B8%B0#:~:text=%EB%98%90%20%EB%8B%A4%EB%A5%B8%20%EA%B3%A0%EB%AF%BC%EC%9D%80%20Server%20to%20Server%ED%98%B8%EC%B6%9C%20%EC%8B%9C%20%EB%AA%A8%EB%91%90%20API%20Gateway%EB%A5%BC%20%EA%B1%B0%EC%B9%A0%20%EA%B2%83%EC%9D%B8%EC%A7%80%20%EC%98%80%EC%8A%B5%EB%8B%88%EB%8B%A4.%2011%EB%B2%88%EA%B0%80%EB%8A%94%20API%EC%84%9C%EB%B2%84%EB%93%A4%EB%81%BC%EB%A6%AC%20%EC%A7%81%EC%A0%91%20%ED%98%B8%EC%B6%9C%ED%95%98%EB%8A%94%20%EB%B0%A9%EC%8B%9D%EC%9D%84%20%EC%82%AC%EC%9A%A9%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4)
        * 게이트웨이는 처리율 제한, SSL, 인증, IP 허용 목록 관리를 지원한다.
* 처리율 제한 알고리즘
    * 토큰버킷
        * 지정된 용량을 갖는 컨테이너로 요청이 처리될 때 마다 하나의 토큰을 사용한다. 버킷 크기, 토큰 공급률(초당 몇 개의 토큰이 버킷에 공급되는가)
        * 엔드포인트마다 별도의 버킷을 둔다.
            * IP 주소마다 버킷을 할 수도 있다
            * 시스템의 처리율을 제한한다면 공통 버킷을 사용한다
        * 장점
            * 구현이 쉽다
            * 메모리 사용도 효율적
            * 버스트 트래픽도 처리 가능
        * 단점
            * 버킷 크기, 토큰 공급률을 튜닝하기 까다롭다
    * 누출 버킷
        * 요청 처리율이 고정되어 있다.
        * FIFO 큐로 구현한다
        * 큐에 빈자리가 있다면 큐에 요청을 추가하고 가득차있다면 요청은 버린다.
        * 지정된 시간마다 큐에서 요청을 꺼내서 처리한다
        * 버킷 크기, 처리율을 인자로 받는다.
        * 장점
            * 큐의 크기가 제한되어 메모리 사용량이 효율적이다
            * 고정된 처리율을 가지고 있어서 안정된 출력이 필요한 경우 적합하다
        * 단점
            * 단시간에 많은 트래픽이 몰리는 경우 큐에 오래된 요청이 쌓이고 제 때 처리못하면 최신 요청이 버려진다
            * 버킷 크기, 처리율에 대한 튜닝이 어렵다
    * 고정 윈도 카운터
        * 타임라인을 고정된 윈도우로 나누고 각 윈도우마다 카운터를 붙인다.
        * 1분마다 윈도우가 초기화된다고하면 윈도우 초기화되는 경계부근에서는 의도한 것보다 많은 요청을 처리할 수 있다.
            * 예를 들어 처리율제한이 1분에 5개인데 2시간 30초~ 2시간 1분에 5개, 2시간 1분 ~2시간 1분 30초에 5개가 들어온다면 2시간 30초~2시간 1분30초에는 10개의 요청이 처리될 수 있다. 윈도우는 2시간 0, 1, 2분에 초기화되기 때문이다.
        * 장점
            * 메모리 효율이 좋다
            * 이해하기 쉽다
            * 윈도우가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다
        * 단점
            * 윈도 경계부근에서 기대했던 것보다 많이 처리한다.
    * 이동 윈도 로그
        * 고정 윈도 카운터를 해결한다.
        * 요청의 타임스탬프를 추적하여 윈도우에 넣는다. 레디스의 정렬 집합을 이용할 수 있다.
        * 새 요청이 오면 윈도우의 시작시점 이전의 타임스탬프를 갖는 것은 제거한다.
        * 로그의 크기가 허용치보다 작거나 같으면 요청을 시스템에 전달한다.
        * 장점
            * 제한 메커니즘은 매우 정교하다. 어느 순간의 윈도우라도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
        * 단점
            * 거부된 요청의 타임스탬프도 갖고있기 때문에 다량의 메모리를 사용
    * 이동 윈도 카운터
        * 고정 윈도 카운터와 이동 윈도 로깅알고리즘을 결합
        * 현재 1분간 요청 수 + 직전 1분간의 요청 수 * 이동윈도와 직전 1분이 겹치는 비율
        * 장점
            * 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계싼하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다
        * 단점
            * 직전 시간대에 도착한 요청이 균등하게 분포된다고 가정하고 추정치를 계산하기 때문에 다소 느슨하다.

## 개략적인 아키텍처
* 처리율제한 알고리즘의 기본 아이디어는 단순하다
* 얼마나 많은 양의 요청이 왔는지를 추적하고 한도를 넘어선 요청은 거부한다.
* 이 카운터를 어디에 보관하는가 => 레디스를 이용할 수 있다.

### 3. 상세 설계
* 처리율 제한 규칙은 어떻게 만들고 어디에 저장되는가?
    * Lyft 는 처리율 제한에 오픈소스를 사용한다.
    * 규칙들은 설정파일 형태로 디스크에 저장한다.
* 처리가 제한된 요청들은 어떻게 처리되는가?
    * HTTP 429
    * X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청 수
    * X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청 수
    * X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지

## 상세 설계
* 클라이언트는 요청을 서버에 보내면 요청은 먼저 처리율 제한 미들웨어에 도달한다.
* 제한 규칙을 캐시에서 가져온다.
    * 제한을 넘지 않는다면 요청은 수용하고 아니라면 HTTP 429 를 반환한다.
* 분산환경에서 처리율 제한 장치의 구현
    * 경쟁조건
        * 레디스에서 카운터의 값을 읽는다.
        * 값이 임계치를 넘는지 보고 넘지 않는다면 증가시킨다.
    * 동기화
        * 고정세션을 활용하여 같은 클라이언트는 같은 서버로 요청을 보낼 수 있으나 규모 확장에서 좋지 않다.
        * 공통 데이터 저장소인 레디스를 활용하자.
    * 성능 최적화
        * 여러 데이터 센터를 지원하는것이 중요하다. 엣지서버를 두는 경우가 있다.
        * 최종 일관성 모델을 사용할 수 있다.
    * 모니터링
        * 알고리즘이 효과적인지
        * 제한 규칙이 효과적인지
            * 너무 빡빡하면 요청이 많이 버려진다.

### 4. 마무리
* 추가적인 주제
    * 경성 / 연성 처리율 제한
    * 다양한 계층에서의 처리율 제한
        * 책에서는 OSI 7번계층(애플리케이션 계층) 의 처리율 제한을 다룸
        * Iptables 를 이용하면 3번계층에서 가능
    * 처리율 제한을 회피하는 방법. 클라이언트 설계는?
        * 클라이언트 측 캐시를 사용하여 API 호출횟수를 줄인다
        * 임계치를 이해하고 짧은 시간 너무 많은 요청을 보내지 않도록 한다
        * 예외나 에러를 처리하는 코드를 도입하여 우아하기 복구될 수 있게 한다
        * 리트라이를 구현할 때는 충분한 백오프 시간을 둔다


### 추가자료
* 멱등성, 실제 리트라이가 필요한 경우
    * https://youtu.be/UOWy6zdsD-c?t=578
